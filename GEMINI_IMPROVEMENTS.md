# ğŸ”§ Geminiå®ç°æ”¹è¿›å»ºè®®

åŸºäºç¤ºä¾‹æ–‡ä»¶ `examples/10_gateway_telegram_bridge.py` å’Œå½“å‰å®ç°çš„å¯¹æ¯”åˆ†æ

---

## ğŸ“Š å½“å‰é—®é¢˜æ€»ç»“

### 1. æ ¹æœ¬é—®é¢˜ï¼šSessionå†å²ç®¡ç†

**ç°çŠ¶**:
- âœ… å·²ä¿®å¤ï¼šæ·»åŠ äº†20æ¡æ¶ˆæ¯é™åˆ¶
- âŒ é—®é¢˜ï¼š71æ¡å†å²æ¶ˆæ¯å¯¼è‡´ä¸Šä¸‹æ–‡æº¢å‡º
- âœ… è§£å†³æ–¹æ¡ˆï¼š`MAX_HISTORY_MESSAGES = 20`

### 2. æ¨¡å‹é…ç½®é—®é¢˜

**å½“å‰é…ç½®**:
```json
{
  "model": "google/gemini-3-pro-preview"
}
```

**ç¤ºä¾‹æ¨è**:
```python
model="gemini/gemini-3-flash-preview"  # æ³¨æ„å‰ç¼€æ˜¯ gemini/ ä¸æ˜¯ google/
```

**Provideræ–‡æ¡£æ¨è**:
```python
# Recommended models (2026):
- gemini-3-flash-preview    # Latest, fastest (RECOMMENDED) â­
- gemini-3-pro-preview      # Most capable
- gemini-2.5-flash          # Stable, fast
- gemini-2.5-pro            # Stable, powerful
```

---

## âœ… å·²å®ç°çš„æ”¹è¿›

### 1. Tool Configä¿®å¤ âœ…
```python
if gemini_tools:
    config_params["tools"] = gemini_tools
    config_params["tool_config"] = types.ToolConfig(
        function_calling_config=types.FunctionCallingConfig(
            mode=types.FunctionCallingConfigMode.AUTO
        )
    )
```

### 2. å†å²æ¶ˆæ¯é™åˆ¶ âœ…
```python
MAX_HISTORY_MESSAGES = 20  # Keep last 20 messages (10 turns)

if len(all_messages) > MAX_HISTORY_MESSAGES:
    system_msgs = [m for m in all_messages if m.role == "system"]
    conversation_msgs = [m for m in all_messages if m.role != "system"]
    recent_conversation = conversation_msgs[-MAX_HISTORY_MESSAGES:]
    messages_to_send = system_msgs + recent_conversation
```

### 3. å¢å¼ºçš„è°ƒè¯•æ—¥å¿— âœ…
```python
logger.info(f"ğŸ“ Sending {len(llm_messages)} message(s) to provider")
logger.info(f"ğŸ“¨ Sending {len(contents)} message(s) to Gemini")
```

### 4. å®‰å…¨è¿‡æ»¤æ£€æµ‹ âœ…
```python
if hasattr(chunk, 'prompt_feedback') and chunk.prompt_feedback:
    feedback = chunk.prompt_feedback
    if hasattr(feedback, 'block_reason') and feedback.block_reason:
        logger.error(f"âŒ CONTENT BLOCKED: {feedback.block_reason}")
```

---

## ğŸ¯ å»ºè®®çš„è¿›ä¸€æ­¥æ”¹è¿›

### æ”¹è¿›1: ä½¿ç”¨æ¨èçš„æ¨¡å‹

**å½“å‰**: `google/gemini-3-pro-preview`  
**æ¨è**: `google/gemini-3-flash-preview`

**åŸå› **:
- `gemini-3-flash-preview` æ˜¯æœ€æ–°ã€æœ€å¿«çš„æ¨¡å‹
- æ›´ä½çš„å»¶è¿Ÿ
- æ›´å¥½çš„æˆæœ¬æ•ˆç›Š
- Provideræ–‡æ¡£æ ‡æ³¨ä¸º"RECOMMENDED"

**å¦‚ä½•ä¿®æ”¹**:
```bash
uv run openclaw config set agents.defaults.model "google/gemini-3-flash-preview"
```

### æ”¹è¿›2: æ·»åŠ ä¸Šä¸‹æ–‡çª—å£ç®¡ç†

**å»ºè®®**: æ ¹æ®æ¨¡å‹åŠ¨æ€è°ƒæ•´å†å²æ¶ˆæ¯æ•°é‡

```python
# æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£é…ç½®
MODEL_CONTEXT_LIMITS = {
    "gemini-3-flash-preview": 32000,    # tokens
    "gemini-3-pro-preview": 128000,     # tokens
    "gemini-2.5-flash": 1000000,        # tokens
}

def calculate_max_history(model_name: str, current_prompt_tokens: int) -> int:
    """æ ¹æ®æ¨¡å‹å’Œå½“å‰promptåŠ¨æ€è®¡ç®—æœ€å¤§å†å²æ¶ˆæ¯æ•°"""
    limit = MODEL_CONTEXT_LIMITS.get(model_name, 32000)
    # ä¿ç•™ 70% ç»™å†å²ï¼Œ30% ç»™å½“å‰promptå’Œå“åº”
    available = int(limit * 0.7)
    # å‡è®¾å¹³å‡æ¯æ¡æ¶ˆæ¯ 200 tokens
    return min(available // 200, 50)  # æœ€å¤š50æ¡
```

### æ”¹è¿›3: å®ç°æ¶ˆæ¯å‹ç¼©ç­–ç•¥

**ç­–ç•¥**: ä¿ç•™é‡è¦æ¶ˆæ¯ï¼Œæ€»ç»“æ—§æ¶ˆæ¯

```python
async def compress_history(messages: list, max_count: int) -> list:
    """
    æ™ºèƒ½å‹ç¼©å†å²æ¶ˆæ¯
    
    ç­–ç•¥:
    1. ä¿ç•™æ‰€æœ‰systemæ¶ˆæ¯
    2. ä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯
    3. å°†ä¸­é—´çš„æ—§æ¶ˆæ¯æ€»ç»“ä¸ºä¸€æ¡æ‘˜è¦
    """
    if len(messages) <= max_count:
        return messages
    
    system_msgs = [m for m in messages if m.role == "system"]
    conv_msgs = [m for m in messages if m.role != "system"]
    
    if len(conv_msgs) <= max_count:
        return messages
    
    # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
    recent = conv_msgs[-max_count:]
    old = conv_msgs[:-max_count]
    
    # ç”Ÿæˆæ‘˜è¦ï¼ˆå¯é€‰ï¼‰
    if len(old) > 5:
        summary = await generate_conversation_summary(old)
        summary_msg = Message(
            role="system",
            content=f"[Earlier conversation summary: {summary}]"
        )
        return system_msgs + [summary_msg] + recent
    
    return system_msgs + recent
```

### æ”¹è¿›4: æ·»åŠ Tokenè®¡æ•°å’Œé¢„è­¦

```python
def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼ˆç²—ç•¥ä¼°è®¡ï¼š1 token â‰ˆ 4 charactersï¼‰"""
    return len(text) // 4

def check_context_length(messages: list, model: str) -> dict:
    """æ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦å¹¶è¿”å›è­¦å‘Š"""
    total_tokens = sum(estimate_tokens(m.content) for m in messages)
    limit = MODEL_CONTEXT_LIMITS.get(model, 32000)
    
    return {
        "total_tokens": total_tokens,
        "limit": limit,
        "usage_percent": (total_tokens / limit) * 100,
        "warning": total_tokens > limit * 0.8,  # 80%é˜ˆå€¼
    }
```

### æ”¹è¿›5: Sessionæ¸…ç†ç­–ç•¥

**è‡ªåŠ¨æ¸…ç†**: å®šæœŸæ¸…ç†æ—§sessions

```python
async def cleanup_old_sessions(workspace_dir: Path, max_age_days: int = 7):
    """æ¸…ç†è¶…è¿‡Nå¤©æœªä½¿ç”¨çš„sessions"""
    import time
    cutoff = time.time() - (max_age_days * 86400)
    
    for session_dir in workspace_dir.glob("telegram-*"):
        # æ£€æŸ¥æœ€åä¿®æ”¹æ—¶é—´
        if session_dir.stat().st_mtime < cutoff:
            logger.info(f"ğŸ—‘ï¸ Cleaning up old session: {session_dir.name}")
            shutil.rmtree(session_dir)
```

### æ”¹è¿›6: é”™è¯¯æ¢å¤æœºåˆ¶

**å½“å‰**: è¿”å›ç©ºå“åº”æ—¶æ²¡æœ‰é‡è¯•  
**æ”¹è¿›**: è‡ªåŠ¨é™çº§å’Œé‡è¯•

```python
async def stream_with_fallback(
    provider: GeminiProvider,
    messages: list,
    tools: list,
    max_retries: int = 2
):
    """
    å¸¦é™çº§ç­–ç•¥çš„æµå¼è°ƒç”¨
    
    é™çº§ç­–ç•¥:
    1. é¦–æ¬¡å¤±è´¥ â†’ å‡å°‘å†å²æ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘5æ¡ï¼‰
    2. å†æ¬¡å¤±è´¥ â†’ ç§»é™¤å·¥å…·
    3. æœ€åå°è¯• â†’ åªå‘é€å½“å‰æ¶ˆæ¯
    """
    attempts = [
        {"messages": messages, "tools": tools, "desc": "å®Œæ•´ä¸Šä¸‹æ–‡"},
        {"messages": messages[-5:], "tools": tools, "desc": "å‡å°‘å†å²"},
        {"messages": messages[-5:], "tools": None, "desc": "ç§»é™¤å·¥å…·"},
        {"messages": messages[-1:], "tools": None, "desc": "ä»…å½“å‰æ¶ˆæ¯"},
    ]
    
    for i, attempt in enumerate(attempts):
        try:
            logger.info(f"å°è¯• {i+1}/{len(attempts)}: {attempt['desc']}")
            
            async for response in provider.stream(
                messages=attempt["messages"],
                tools=attempt["tools"]
            ):
                yield response
            
            return  # æˆåŠŸï¼Œé€€å‡º
            
        except Exception as e:
            logger.warning(f"å°è¯• {i+1} å¤±è´¥: {e}")
            if i == len(attempts) - 1:
                raise  # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
```

---

## ğŸ“‹ å®æ–½ä¼˜å…ˆçº§

### P0 (ç«‹å³æ‰§è¡Œ)
- [x] âœ… ä¿®å¤tool_config
- [x] âœ… æ·»åŠ å†å²æ¶ˆæ¯é™åˆ¶
- [ ] ğŸ”„ æ¸…ç†ç°æœ‰sessions
- [ ] ğŸ”„ é‡å¯GatewayéªŒè¯

### P1 (çŸ­æœŸ)
- [ ] åˆ‡æ¢åˆ° `gemini-3-flash-preview`ï¼ˆæ›´å¿«æ›´ä¾¿å®œï¼‰
- [ ] æ·»åŠ Tokenè®¡æ•°å’Œé¢„è­¦
- [ ] å®ç°é”™è¯¯æ¢å¤æœºåˆ¶

### P2 (ä¸­æœŸ)
- [ ] å®ç°æ™ºèƒ½æ¶ˆæ¯å‹ç¼©
- [ ] æ·»åŠ è‡ªåŠ¨sessionæ¸…ç†
- [ ] ä¼˜åŒ–æ—¥å¿—è¾“å‡ºï¼ˆå‡å°‘å†—ä½™ï¼‰

### P3 (é•¿æœŸ)
- [ ] å¤šæ¨¡å‹è´Ÿè½½å‡è¡¡
- [ ] åŸºäºç”¨æˆ·çš„é…ç½®ï¼ˆVIPç”¨æˆ·ç”¨proï¼Œæ™®é€šç”¨æˆ·ç”¨flashï¼‰
- [ ] å®æ—¶Tokenä½¿ç”¨ç»Ÿè®¡

---

## ğŸ” ä¸TypeScriptç‰ˆæœ¬çš„å¯¹é½

### æ¶æ„å¯¹é½ âœ…
```
TypeScript OpenClaw:
  Gateway â†’ ChannelManager â†’ Channels â†’ Agent Runtime

Python OpenClaw:
  Gateway â†’ ChannelManager â†’ Channels â†’ Agent Runtime
  âœ… å®Œå…¨ä¸€è‡´
```

### Sessionç®¡ç† âš ï¸
**TypeScript**: å¯èƒ½ä¹Ÿæœ‰ç±»ä¼¼çš„å†å²é™åˆ¶  
**Python**: å·²æ·»åŠ ï¼Œä½†éœ€è¦éªŒè¯ä¸TSç‰ˆæœ¬çš„ä¸€è‡´æ€§

### æ¨¡å‹é…ç½® âš ï¸
**TypeScript**: éœ€è¦æ£€æŸ¥é»˜è®¤æ¨¡å‹  
**Python**: å½“å‰ä½¿ç”¨ `gemini-3-pro-preview`

---

## ğŸ§ª éªŒè¯æ¸…å•

### éªŒè¯æ­¥éª¤

1. **æ¸…ç†æ—§æ•°æ®**:
   ```bash
   rm -rf ~/.openclaw/workspace/telegram-*
   ```

2. **é‡å¯Gateway**:
   ```bash
   uv run openclaw gateway run
   ```

3. **æµ‹è¯•å¯¹è¯**:
   ```
   ä½ : ä½ å¥½
   Bot: [åº”è¯¥ç«‹å³æ”¶åˆ°å›å¤] âœ…
   
   ä½ : [è¿›è¡Œ20è½®å¯¹è¯]
   æ—¥å¿—: "âš ï¸ Context too long! Truncating..." âœ…
   ```

4. **æ£€æŸ¥æ—¥å¿—**:
   ```
   ğŸ“ Sending 1 message(s) to provider  â† ç¬¬ä¸€æ¡
   ğŸ“ Sending 20 message(s) to provider â† è¾¾åˆ°ä¸Šé™
   âš ï¸ Context too long! Truncating from 71 to 20 â† è‡ªåŠ¨æˆªæ–­
   ```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ä¿®å¤å‰
- æ¶ˆæ¯æ•°é‡: 71æ¡ï¼ˆæ‰€æœ‰å†å²ï¼‰
- ä¼°ç®—Tokens: ~14,000+ tokens
- Geminiå“åº”: âŒ ç©ºå“åº”
- ç”¨æˆ·ä½“éªŒ: âŒ Botä¸å›å¤

### ä¿®å¤å
- æ¶ˆæ¯æ•°é‡: â‰¤20æ¡ï¼ˆæœ€è¿‘å†å²ï¼‰
- ä¼°ç®—Tokens: ~4,000 tokens
- Geminiå“åº”: âœ… æ­£å¸¸
- ç”¨æˆ·ä½“éªŒ: âœ… æ­£å¸¸å¯¹è¯

---

## ğŸ¯ æ¨èçš„æœ€ç»ˆé…ç½®

```json
{
  "agents": {
    "defaults": {
      "model": "google/gemini-3-flash-preview",  // æœ€å¿«çš„æ¨¡å‹
      "workspace": "~/.openclaw/workspace",
      "tools": {
        "profile": "full"
      },
      "history": {
        "max_messages": 20,        // å†å²æ¶ˆæ¯é™åˆ¶
        "auto_cleanup_days": 7      // è‡ªåŠ¨æ¸…ç†
      }
    }
  }
}
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **ç¤ºä¾‹æ–‡ä»¶**: `examples/10_gateway_telegram_bridge.py`
   - å±•ç¤ºäº†å®Œæ•´çš„æ¶æ„
   - ä½¿ç”¨ `gemini-3-flash-preview`

2. **Gemini Provider**: `openclaw/agents/providers/gemini_provider.py`
   - æ¨èæ¨¡å‹åˆ—è¡¨
   - APIä½¿ç”¨æ–¹å¼

3. **Runtime**: `openclaw/agents/runtime.py`
   - Sessionç®¡ç†
   - æ¶ˆæ¯æ„é€ é€»è¾‘

---

## âœ… æ€»ç»“

**å·²è§£å†³çš„æ ¸å¿ƒé—®é¢˜**:
1. âœ… 71æ¡å†å²æ¶ˆæ¯å¯¼è‡´ä¸Šä¸‹æ–‡æº¢å‡º
2. âœ… ç¼ºå°‘tool_configå¯¼è‡´ç©ºå“åº”
3. âœ… æ·»åŠ äº†è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—

**ä¸‹ä¸€æ­¥**:
1. ğŸ”„ æ¸…ç†æ—§sessionså¹¶é‡å¯éªŒè¯
2. ğŸ“ è€ƒè™‘åˆ‡æ¢åˆ° `gemini-3-flash-preview`
3. ğŸ”§ å®ç°Tokenè®¡æ•°å’Œé¢„è­¦

**é•¿æœŸä¼˜åŒ–**:
- æ™ºèƒ½æ¶ˆæ¯å‹ç¼©
- è‡ªåŠ¨sessionæ¸…ç†
- å¤šæ¨¡å‹è´Ÿè½½å‡è¡¡

---

**æœ€åæ›´æ–°**: 2026-02-12  
**çŠ¶æ€**: æ ¸å¿ƒé—®é¢˜å·²ä¿®å¤ï¼Œç­‰å¾…éªŒè¯
